# Advanced RAG: A Practical Guide to Contextual Chunking

![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)
![Python 3.9+](https://img.shields.io/badge/python-3.12+-blue.svg)

This repository contains the code and article for "Contextual Chunking for Retrieval Augmented Generation," a deep dive into building more accurate and reliable RAG systems for complex, structured enterprise documents.

The goal of this project is to move beyond simplistic fixed-size chunking and demonstrate a superior method that preserves the logical structure of documents, ensuring the context passed to Large Language Models (LLMs) is both **complete** and **relevant**.

## The Problem: Why Standard Chunking Fails

In enterprise settings, documents like technical manuals, financial reports, and legal contracts are highly structured. They contain hierarchies, sections, and complex elements like multi-page tables.

Standard fixed-size chunking ignores this structure, often leading to critical failures:
- **Incomplete Context**: A 5-page table might be split across multiple, disconnected chunks, making it impossible for an LLM to retrieve the full table.
- **Irrelevant Context**: Chunks may include unrelated information from adjacent sections, confusing the LLM and leading to inaccurate answers.

For digital transformation projects where precision is paramount, these failures can render an AI solution unusable.

## This Repository: A Practical Solution

This repository provides a hands-on guide and the complete Python code to implement **contextual chunking**. We demonstrate how to leverage a document's inherent structure to create meaningful chunks that respect its logical boundaries.

### Key Features:
*   **In-depth Article**: The full analysis and methodology are detailed in this [article](https://dev.to/lewis_won/contextual-chunking-for-retrieval-augmented-generation-3lha). The Jupyter notebook to follow along is `contextual_chunking.ipynb`.
*   **Baseline Comparison**: Code to demonstrate the shortcomings of fixed-size chunking.
*   **Advanced Implementation**: A full Python implementation of contextual chunking using Google's Gemini 2.5 Pro to generate structural metadata.
*   **End-to-End Pipeline**: The code covers everything from document parsing and metadata generation to chunking, embedding, retrieval, and reranking.
*   **Reproducible Experiments**: Follow along with the provided sample document and Jupyter notebooks to see the results for yourself.

## Getting Started

Follow these instructions to set up your local environment and run the experiments.

### Prerequisites
*   Python 3.12 or higher
*   Git
*   A Google API Key with access to the Gemini API.

### Installation

1.  **Clone the repository:**
    ```sh
    git clone https://github.com/searlion/rag-strategies.git
    cd rag-strategies
    ```

2.  **Create and activate a virtual environment:**
    ```sh
    uv venv
    source .venv/bin/activate
    ```

3.  **Install the required dependencies:**
    ```sh
    uv lock
    ```

4.  **Set up your environment variables:**
    Create a file named `.env` in the root of the project and add your Google API key:
    ```
    GEN_API_KEY="YOUR_GOOGLE_API_KEY_HERE"
    ```
    The code will automatically load this key.

## How to Run the Experiments

The core logic is contained in the Jupyter notebook `contextual_chunking.ipynb` for easy, step-by-step execution.

## Project Structure

```
.
├── contextual_chunking.ipynb                                            # The Jupyter notebook for following along.
├── resources/
│   └── firds_reference_data_functional_specifications_v2.10.pdf         # The sample document used in the experiments.
├── parsed/
│   └── section_map.json                                                 # The metadata generated by Gemini.
│   └── firds_reference_data_functional_specifications_v2.10.md          # The markdown parsed by Docling.
├── pyproject.toml                                                       # Project dependencies.
├── .env.example                                                         # Example environment file.
└── README.md                                                            # You are here!
```

## Contributing

**Contributions are welcome and highly encouraged!**

This project is a starting point. There are many ways to improve and expand upon this work. If you have an idea, a bug fix, or a suggestion, please feel free to open an issue or submit a pull request.

### How to Contribute:
1.  **Fork** the project.
2.  Create your **Feature Branch** (`git checkout -b feature/AmazingFeature`).
3.  **Commit** your changes (`git commit -m 'Add some AmazingFeature'`).
4.  **Push** to the branch (`git push origin feature/AmazingFeature`).
5.  Open a **Pull Request**.

Areas for contribution could include:
*   Trying different LLMs for metadata generation.
*   Experimenting with alternative document parsing libraries.
*   Improving the prompt for Gemini.
*   Adding support for different document formats (e.g., DOCX, HTML).
*   Optimizing the retrieval and reranking pipeline.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.